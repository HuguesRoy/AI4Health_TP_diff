{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352d017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from data import BraTSAD\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38271c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_path = Path(\"/Users/hugues.roy/Documents/BraTS2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e40176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n",
      "Loaded 4211 normal images, 5.703s\n"
     ]
    }
   ],
   "source": [
    "brats_data = BraTSAD(\n",
    "    main_path=brats_path,\n",
    "    img_size=64,\n",
    "    mode=\"train\",\n",
    "    test_type=None,\n",
    "    transform= transforms.ToTensor())\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    brats_data,\n",
    "    batch_size=1,)\n",
    "\n",
    "save_path = Path(\"/Users/hugues.roy/Documents/programming/IA4Health_TP_diff/BraTS2021/train\")\n",
    "\n",
    "for i, data in enumerate(data_loader):\n",
    "\n",
    "    img = data['img'].squeeze(0)\n",
    "    name = data['name'][0]\n",
    "\n",
    "    torch.save(img, save_path /f\"{name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96b71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 2 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m brats_data = \u001b[43mBraTSAD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmain_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbrats_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabnormal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m data_loader = torch.utils.data.DataLoader(\n\u001b[32m      9\u001b[39m     brats_data,\n\u001b[32m     10\u001b[39m     batch_size=\u001b[32m1\u001b[39m,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/IA4Health_TP_diff/data/data.py:77\u001b[39m, in \u001b[36mBraTSAD.__init__\u001b[39m\u001b[34m(self, main_path, img_size, transform, mode, test_type, context_encoding)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.labels += \u001b[38;5;28mlen\u001b[39m(test_abnormal) * [\u001b[32m1\u001b[39m]\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.img_ids += [img_name.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m test_l]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLoaded \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m test normal images, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m test abnormal images. \u001b[39;49m\u001b[38;5;132;43;01m{:.3f}\u001b[39;49;00m\u001b[33;43ms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_abnormal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m     test_normal_dir = os.path.join(\u001b[38;5;28mself\u001b[39m.root, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnormal\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: Replacement index 2 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "brats_data = BraTSAD(\n",
    "    main_path=brats_path,\n",
    "    img_size=64,\n",
    "    mode=\"test\",\n",
    "    test_type=\"abnormal\",\n",
    "    transform= transforms.ToTensor())\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    brats_data,\n",
    "    batch_size=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c7f9bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'label': 0,\n",
       " 'name': 'BraTS2021_01622_flair_61',\n",
       " 'mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brats_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"/Users/hugues.roy/Documents/programming/IA4Health_TP_diff/BraTS2021/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73668e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_loader):\n",
    "\n",
    "    img = data['img'].squeeze(0)\n",
    "    name = data['name'][0]\n",
    "\n",
    "    torch.save(img, save_path /f\"{name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ebd370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BraTS2021_01222_flair_25'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60060480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_normal = os.listdir(brats_path / \"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinicadl_beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
